{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "53683d23-123f-4b11-85f3-0c79354276eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read all input data: 0.002 sec\n",
      "Processing: ByteWorks\n",
      "Processing: CodeWave\n",
      "Processing: LogicLabs\n",
      "Processing: MindMeld\n",
      "Processing: PixelPulse\n",
      "Processing: TechTonic\n",
      "Processing: SynapseSoft\n",
      "Processing: ByteBuilders\n",
      "Processing: CyberCore\n",
      "Processing: DataDreams\n",
      "Processing: Tessitura\n",
      "Processing: Bits of Stock\n",
      "Processing: Pluto Health\n",
      "Processing: Leadstack Inc\n",
      "Processing: Avalon Healthcare Solutions\n",
      "Processing: Pragma Platform\n",
      "Processing: ConsultingLLC\n",
      "Processing: AIWorks\n",
      "Processing: TechMatters\n",
      "Processing: All Infra\n",
      "Done Processing: 21 - Time: 199.602 sec\n",
      "Output file: processed_job_offers.csv\n",
      "Done! - Total Time: 199.605 sec\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import csv\n",
    "from io import StringIO\n",
    "import time\n",
    "\n",
    "# Track execeution time\n",
    "start = time.time()\n",
    "\n",
    "# Input files\n",
    "gpt_api_file = \"gpt-api.key\"\n",
    "summarized_cv_file = \"summarized_cv.txt\"\n",
    "job_offers_csv_file = \"job_offers.csv\"\n",
    "output_file = \"processed_job_offers.csv\"\n",
    "\n",
    "# Set up the API key\n",
    "openai.api_key\n",
    "with open(gpt_api_file, \"r\") as file:\n",
    "    # Read the first line of the file\n",
    "    openai.api_key = file.readline()\n",
    "\n",
    "# Load Data (CV and job offers)\n",
    "summarized_cv\n",
    "with open(summarized_cv_file, \"r\", encoding='utf-8') as file:\n",
    "    # Read the first line of the file\n",
    "    summarized_cv = file.readline()\n",
    "\n",
    "job_offers\n",
    "with open(job_offers_csv_file, 'r', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    job_offers = list(reader)\n",
    "\n",
    "# Add columns for structuring results\n",
    "job_offers[0].append(\"met\")\n",
    "job_offers[0].append(\"unmet\")\n",
    "job_offers[0].append(\"match\")\n",
    "column_names = job_offers[0]\n",
    "\n",
    "elapsed = time.time()\n",
    "print(\"Read all input data: \" + \"{:.3f}\".format(elapsed - start) + \" sec\")\n",
    "\n",
    "# Collect ChatGPT Responses for each job_offer\n",
    "for job in job_offers[1:]:\n",
    "    \n",
    "    # Add extra columns to the current job\n",
    "    job.append(\"met\")\n",
    "    job.append(\"unmet\")\n",
    "    job.append(\"match\")\n",
    "    \n",
    "    # Generate Prompt\n",
    "    prompt = \"Given my profile and this job offer, list which requirements are met or not. Provide the results in csv format with columns separated by a pipe: requirement|status (met/unmet) \\n - my profile: \" + summarized_cv + \" \\n - job offer: \" + job[column_names.index('description')]   \n",
    "    print(\"Processing: \" + job[column_names.index('company')]) # debug info\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a chatbot\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ],\n",
    "            timeout=30\n",
    "        )\n",
    "       \n",
    "        result = ''\n",
    "        for choice in response.choices:\n",
    "            result += choice.message.content\n",
    "        # print(result) # debug info\n",
    "\n",
    "        # Extract result from response and turn into matrix\n",
    "        parsed_result = StringIO(result)\n",
    "        result_reader = csv.reader(parsed_result, delimiter='|')\n",
    "        result_matrix = list(result_reader)\n",
    "\n",
    "        # print(result_matrix) # debug info\n",
    "        # Evaluate if result matches the requested structure -> otherwise flag and skip\n",
    "        result_column_names = result_matrix[0]\n",
    "        if 'requirement' in result_column_names[0].lower() and 'status' in result_column_names[1].lower(): \n",
    "             # Iterate over results\n",
    "            met_reqs = \"\"\n",
    "            unmet_reqs = \"\"\n",
    "            for requirement in result_matrix[1:]:\n",
    "                # collect met/unmet\n",
    "                try:\n",
    "                    if requirement[1].lower() == 'met':\n",
    "                        met_reqs += \"- \" + requirement[0] + \"\\n\"\n",
    "                    else:\n",
    "                        unmet_reqs += \"- \" + requirement[0] + \"\\n\"\n",
    "                except IndexError: \n",
    "                    # The response does not meet the requested structure\n",
    "                    print(\"Error Processing Response: \" + str(requirement))\n",
    "\n",
    "            # calculate metric - check that at least one req was processed\n",
    "            total_reqs = len(met_reqs) + len(unmet_reqs)\n",
    "            if total_reqs > 0:\n",
    "                match = len(met_reqs) / total_reqs * 100\n",
    "            else:\n",
    "                match = 'Error Processing Response'\n",
    "\n",
    "            # append results to row\n",
    "            job[column_names.index('met')] = met_reqs\n",
    "            job[column_names.index('unmet')] = unmet_reqs\n",
    "            job[column_names.index('match')] = match\n",
    "        else:\n",
    "            print(\"Error while reading ChatGPT response to job offer: \" + str(job))\n",
    "            print(\"Response: \" + str(result_matrix))\n",
    "            job.append(\"met\")\n",
    "            job.append(\"unmet\")\n",
    "            job.append(\"match\")\n",
    "            job[column_names.index('met')] = \"Error: could not process this job offer\"\n",
    "            job[column_names.index('unmet')] = \"Error: could not process this job offer\"\n",
    "            job[column_names.index('match')] = \"Error: could not process this job offer\"\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"Request timed out\")\n",
    "        job[column_names.index('met')] = \"Error: Requested Timed out\"\n",
    "        job[column_names.index('unmet')] = \"Error: Requested Timed out\"\n",
    "        job[column_names.index('match')] = \"Error: Requested Timed out\"\n",
    "\n",
    "elapsed = time.time()\n",
    "print(\"Done Processing: \" + str(len(job_offers)-1) + \" - Time: \" + \"{:.3f}\".format(elapsed - start) + \" sec\")\n",
    "\n",
    "    \n",
    "# Write output file\n",
    "# Debug output\n",
    "#for row in job_offers:\n",
    "#    print(str(row[0]) + \" \" + str(row[1]) + \" \" + str(row[4]) + \" \" + str(row[5]) + \" \" + str(row[6]))\n",
    "with open(output_file, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the data to the CSV file\n",
    "    writer.writerows(job_offers)\n",
    "\n",
    "print(\"Output file: \" + output_file)\n",
    "elapsed = time.time()\n",
    "print(\"Done! - Total Time: \" + \"{:.3f}\".format(elapsed - start) + \" sec\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
